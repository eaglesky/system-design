

Knowledge:

1. Network.

1.1 How does webserver work with browser?
https://aprelium.com/data/doc/2/abyssws-linux-doc-html/howdowswork.html

1.2 Web server(http server) vs application server.
http://www.javaworld.com/article/2077354/learn-java/app-server-web-server-what-s-the-difference.html
http://stackoverflow.com/questions/936197/what-is-the-difference-between-application-server-and-web-server/936257#936257
App server often includes web server. Web server is mainly responsible for receiving
requests and return static html contents, while app server has more complex business
logic that processes the request. Web servers provide the caching and scaling functionality
demanded by web access, while app servers provide application level services such
as connection pooling, object pooling, transaction support, messaging services etc.

1.3 Web hosting service
A web hosting service is a type of Internet hosting service that allows individuals
and organizations to make their website accessible via the World Wide Web. Web hosts
are companies that provide space on a server owned or leased for use by clients, as
well as providing Internet connectivity, typically in a data center.
Example: Bluehost, Dreamhost, Go Daddy, Host Gator, pair Networks.

Different types of web hosting service
Shared, dedicated, VPS, Cloud.
https://hostingfacts.com/different-types-of-web-hosting/.

1.4 Computer Protocols- TCP/IP, POP, SMTP, HTTP, FTP and More
http://vlaurie.com/computers2/Articles/protocol.htm

1.4.1 TCP vs UDP
https://www.howtogeek.com/190014/htg-explains-what-is-the-difference-between-tcp-and-udp/
UDP is less reliable but much faster, so it is preferable for transmitting time-critical
data, like live video stream and online game data.

1.4.2 Ports
Open tcp port 80(http) and tcp port 443(https) for the traffic coming into the LBs.
Opening tcp port 80 for the inside traffic after first layer of LB can save putting
SSL certificate on all of the web servers.
Open tcp port 3306(MySQL db server default)

1.5 Cookies
Http Cookies and third-party cookies.
Drawbacks of cookies:https://en.wikipedia.org/wiki/HTTP_cookie#Drawbacks_of_cookies

1.6 Sessions.
http://stackoverflow.com/questions/3804209/what-are-sessions-how-do-they-work
Three ways of managing sessions:
https://www.youtube.com/watch?v=32UGARg8AzU
Cookies
URL rewriting, Hidden fields
https://www.youtube.com/watch?v=xGAVFsLfn2w
https://www.youtube.com/watch?v=Pv3FST7OcvQ

2. Load balacing:
The DNS server can return the ip of load balancer instead of a server, and let the
load balancer decide which server the request should be sent to.

2.1 Load balancing strategies:
(1) Based on load of the server(how busy it is, the cpu usage, or the number of connections).
(2) Store different types of files on different servers, and use the suffix of url
to discreminate them. 
(3) Round robin. Example: BIND(the most widely used Domain Name System (DNS) software
on the Internet) uses this strategy to resolve a host name --- same host name, but
different ip each time. The drawback of this strategy is that one or few server could
always receive requests that require most computation resource, making them much busier
than the rest. Another thing that can show it is a bad strategy is DNS caching, which
exists on the user's computer(maintained by the OS and browser). This caching is a
map of host name and ip address that will expire(clear) after a certain amount of
time(TTL). It is only used for speeding up the response time 
(https://www.lifewire.com/introduction-to-domain-name-system-817512). So if an user
keeps doing expensive work, it will always be done on the same server during TTL and
that server will be always busy. Therefore instead of relying on the DNS server to
do the load balancing, it is better to let the DNS server return the ip of the load
balancer.

Server-side sessions could cause problems for load balancing, because one session
for a user is only stored on one server. Solution: store all the sessions on a dedicated
session server, or the load balancer itself, which can be accessed by all servers.
However what if the server is down?
We could try using RAID to achieve data redundancy to some degree, but this is still
not a good solution, as it is possible that the whole server is down. A better way
to deal with it is to use multiple servers, which requires some syncing process.
Sticky session can also be a solution here, which can be implemented by storing an
id in the user's cookie and let LB to remember the mapping of that id to the ip of
the server the session belongs to.

* RAID(Redundant array of inexpensive disks):
It is a data storage virtualization technology that combines multiple physical disk
drive components into a single logical unit for the purposes of data redundancy,
performance improvement, or both.

RAID0: Uses data striping(technique of segmenting logically sequential data, such
as a file, so that consecutive segments are stored on different physical storage
devices) to perform concurrent read and write, so that the performance could be improved
by the number of disks. No data redundancy involved.

RAID1: Uses data mirroring to implement redundancy. Typically two idendical hard drives.
Write throughput is always slower because every drive must be updated, and the slowest
drive limits the write performance. 

RAID10: A combination of above.

2.2 Load Balancer choices:
Software:
ELB(AWS Elastic Load Balancing), HAProxy, LVS(Linux Virtual Server, http://www.linuxvirtualserver.org/whatis.html)
Hardware:
Barracuda, Cisco, Citrix, F5..

3. Caching.

3.1 Cache could be in memory or on the disk, client side or server side.
Examples:
(1) File based caching. Storeing a new file(html file) when new data is entered, like
what is done by Craigslist. The upside of this approach is that the html file doesn't
have to be regenerated everytime it's visited. The downside of it is due to the redundancy,
it is hard to change the common style of the pages. And it could use too much space.
(2) MySQL caching.
query_cache_type = 1 is enough to enable it. Used for cache the query result.
(3) Memcached
Cache data and objects in the RAM. Use LRU to purge old data when it is full.

3.2 Local cache and distributed cache.

3.2.1 Local cache
A cache could be local to an application instance and stored in-memory.
It is private and so different application instances could each have a copy of the
same cached data. This data could quickly become inconsistent between caches(because
after one write request sent to an application server, the server will update the
data and update/invalidate the corresponding one in the associated cache, making
it differ from the rest), so it may be necessary to expire data held in a private
cache and refresh it more frequently. In these scenarios it may be appropriate
to investigate the use of a shared or a distributed caching mechanism.

3.2.2. Distributed cache: A distributed cache may span multiple servers so that it
can grow in size and in transactional capacity.
http://stackoverflow.com/questions/15457910/what-is-a-distributed-cache

3.2.3. Comparison of the two:
https://dzone.com/articles/process-caching-vs-distributed

3.2.4. Caching patterns.
* Cache-aside pattern:
https://blog.cdemi.io/design-patterns-cache-aside-pattern/
Example: Memcached + MySQL
Memcached is just a cache, not a database!
* Cache-through pattern:
Cache handles the requests from the web server and persisit the data to the backed
databased. E.g. Redis.

3.2.5. Caching query result vs caching the objects(?)
http://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache

4. Database.

4.1. Database storage engine.
A database storage engine is the underlying software that a DBMS uses to create,read,
update and delete data from a database. The storage engine should be thought of as
a “bolt on” to the database (server daemon), which controls the database’s interaction
with memory and storage subsystems. Thus, the storage engine is not actually the database,
but a service that the database consumes for the storage and retrieval of information.
Given that the storage engine is responsible for managing the information stored
in the database, it greatly affects the overall performance of the database (or
lack thereof, if the wrong engine is chosen).
https://www.percona.com/blog/2016/01/06/mongodb-revs-you-up-what-storage-engine-is-right-part-1/
E.g., MyISAM, InnoDB, Memory, Archive, NDB..
MyISAM vs InnoDB(default of MySQL):http://blog.danyll.com/myisam-vs-innodb/
Comparison of all: http://zetcode.com/databases/mysqltutorial/storageengines/
Database engines are responsible for indexing, according to Wikipedia.

4.2. Database indexing.
http://www.programmerinterview.com/index.php/database-sql/what-is-an-index/
Typically database index is a datastructure like B tree(non-binary self-balancing
tree)

4.3. Database normalization and denormalization.
https://www.essentialsql.com/get-ready-to-learn-sql-database-normalization-explained-in-simple-english/
http://www.vertabelo.com/blog/technical-articles/denormalization-when-why-and-how

4.4. ACID transaction.
* Atomicity. In a transaction involving two or more discrete pieces of information,
either all of the pieces are committed or none are.
* Consistency. A transaction either creates a new and valid state of data, or, if
any failure occurs, returns all data to its state before the transaction was started.
* Isolation. A transaction in process and not yet committed must remain isolated
from any other transaction.
* Durability. Committed data is saved by the system such that, even in the event of
a failure and system restart, the data is available in its correct state.

4.5. Ways of improving database query performance.
* Optimizing the query itself, add caching.
* Indexing.
* Denormalization.

4.6. DBMS types:
https://www.youtube.com/watch?v=jSXxrTNZwXA
Relational, Use SQL: MySQL
Object-oriented, Use OQL: ObjectDB.
NoSQL.

4.7. Distributed databases(NoSQL).



Why NoSQL?
NoSQL encompasses a wide variety of different database technologies that were developed
in response to the demands presented in building modern applications:
* Developers are working with applications that create massive volumes of new, rapidly
changing data types — structured, semi-structured, unstructured and polymorphic data.
* Long gone is the twelve-to-eighteen month waterfall development cycle. Now small
teams work in agile sprints, iterating quickly and pushing code every week or two,
some even multiple times every day.
* Applications that once served a finite audience are now delivered as services that
must be always-on, accessible from many different devices and scaled globally to
millions of users.
* Organizations are now turning to scale-out architectures using open source software,
commodity servers and cloud computing instead of large monolithic servers and storage
infrastructure.
Relational databases were not designed to cope with the scale and agility challenges
that face modern applications, nor were they built to take advantage of the commodity
storage and processing power available today.

